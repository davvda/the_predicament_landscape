<title>Faulty meta-optimisation</title>
<h2>Faulty meta-optimisation</h2>
<p><strong>Meta-optimisation is optimising what you're optimising</strong>. In simpler terms, it is prioritisation. Every action we take can be seen as contributing to one long optimisation equation, consciously or not. There are times when what you optimise for is obvious, perhaps buying a car that maximises convenience while minimising cost. Most times, however, what you're optimising for is complicated and multi-faceted. Furthermore, many systems incentivise us to optimise badly. This is where meta-optimisation comes in. How do you make sure that if you want to optimise for a "life well lived", you have (meta)optimised your optimisation equation to actually yield that result? Now, this is an unanswerable question or, rather, it is a question you can spend several lives trying to answer, but while the perfect optimisation doesn't exist and constantly changes it is quite clear when an optimisation equation hasn't been correctly (meta)optimised. When this fact appears in stark relief, something has to change. When variables such as wealth keep increasing while variables such as time spent in old-growth forests (apologies to any hippiephobe), enjoyment of music, or pure joy have stopped increasing and may even be decreasing we have to re-meta-optimise.</p>
<p>Lastly, there is of course also the question of meta-meta-optimisation and meta-meta-meta-optimisation but that becomes a bit too meta at this time, even for me.</p>
<p><strong>Outgoing connections:</strong></p>
<ul>
	<li><strong><a href="Acceleration.html">Acceleration</a></strong> - We have meta-optimised for speed and growth.</li>
	<li><strong><a href="Artificial intelligence.html">Artificial intelligence</a></strong> - If we deem an artificial intelligence particularly intelligent, what do we mean by that? Do we mean that it seems to optimise for the same things we optimise for? Should it? Or is the way AIs "think" reflecting how we are already selecting what human intelligence means? Which minds are rising to the top of the power struggle? Do the way they "think" reflect what most humans optimise for?</li>
	<li><strong><a href="Being reasonable.html">Being reasonable</a></strong> - How could you reasonably and rationally optimise for what creates more beauty, life, or love?</li>
	<li><strong><a href="Biased evidence selection.html">Biased evidence selection</a></strong></li>
	<li><strong><a href="Capitalism.html">Capitalism</a></strong> - We're meta-optimising for wellbeing and happiness by optimising proxies that no longer show clear correlations for either of the two.</li>
	<li><strong><a href="Car-centric design.html">Car-centric design</a></strong> - Optimise for speed and you might get cars, optimise for cars and you get car-centric urban development.</li>
	<li><strong><a href="Cognitive dissonance.html">Cognitive dissonance</a></strong> - If you are attempting to optimise for a well-lived life and it isn't happening from optimising what modernity allows you to... What's the deal?</li>
	<li><strong><a href="Dealing with death.html">Dealing with death</a></strong> - Why are we trying to beat death when we haven't yet figured out neither how to live well or to die well?</li>
	<li><strong><a href="Delusional domination of nature.html">Delusional domination of nature</a></strong> - Even if the domination was to be non-delusional, how would the ability to dominate nature benefit natural beings?</li>
	<li><strong><a href="Directionlessness.html">Directionlessness</a></strong></li>
	<li><strong><a href="Ecological crisis.html">Ecological crisis</a></strong></li>
	<li><strong><a href="Educational crisis.html">Educational crisis</a></strong> - When we design educational curricula, what are we optimising for? Is it working? Assuming benevolent and thoroughly considered intentions, are schools transitioning children towards becoming intelligent, independent, sociable, creative, contributing, caring, wise, healthy, fit, friendly, mature, communicative, strong adults? Plain laughable, sadly. But are those intentions actually our meta-optimised variables? I doubt it. Simply producing human machines fit for the workforce gets closer to the truth, I think.</li>
	<li><strong><a href="Ego.html">Ego</a></strong> - How many things in life have been maximised to serve the ego above all others?</li>
	<li><strong><a href="End of history.html">End of history</a></strong> - Our faulty meta-optimisation, our failure to have our highest intentions filter through the layers undisturbed all the way to the actions of our feet on the Earth, this is our big failing as a species.</li>
	<li><strong><a href="Energy.html">Energy</a></strong> - Any natural optimisation is chiefly about energy extraction and consumption.</li>
	<li><strong><a href="Energy consumption increasing.html">Energy consumption increasing</a></strong></li>
	<li><strong><a href="Evil.html">Evil</a></strong> - Meta-optimisation going just slightly wrong quickly lead to acts of evil.</li>
	<li><strong><a href="Finite games.html">Finite games</a></strong> - Our initial strategy and tactics never considered the inevitable end of finite games.</li>
	<li><strong><a href="Growth.html">Growth</a></strong> - Optimising is about maximising.</li>
	<li><strong><a href="Hemispherical asymmetry (Brain).html">Hemispherical asymmetry (Brain)</a></strong></li>
	<li><strong><a href="Illusion of competence.html">Illusion of competence</a></strong> - Everything seemed to be going so well. If reality caught up, how did we leave it behind in the rush to begin with?</li>
	<li><strong><a href="Immoral justifications.html">Immoral justifications</a></strong> - What happens to us when our welfare depends on arms export, extractivism, or deforestation? What arrows turn back from one optimisation to the other, pointing at weapons, mines, and razed forests as being opposite to welfare? These insights shouldn't be difficult or deep, are we this tolerant to moral failure?</li>
	<li><strong><a href="Individualism.html">Individualism</a></strong></li>
	<li><strong><a href="Inertia.html">Inertia</a></strong> - We are stuck in the inertia of previous meta-optimisations that were never intended to be maintained this long.</li>
	<li><strong><a href="Lack of balance.html">Lack of balance</a></strong></li>
	<li><strong><a href="Lack of historical insight.html">Lack of historical insight</a></strong></li>
	<li><strong><a href="Lack of purpose.html">Lack of purpose</a></strong> - Entrenched in following the instructions of a manual we no longer have the required parts for.</li>
	<li><strong><a href="Lack of resilient systems.html">Lack of resilient systems</a></strong></li>
	<li><strong><a href="Lack of the longterm.html">Lack of the longterm</a></strong> - Some time during the past century, most of modern civilisation lost what it was built upon. It lost the future.</li>
	<li><strong><a href="Map and territory.html">Map and territory</a></strong> - Optimisations are scribbles on a map.</li>
	<li><strong><a href="Meaning crisis.html">Meaning crisis</a></strong></li>
	<li><strong><a href="Moloch.html">Moloch</a></strong> - Moloch was, at the early stages of our optimisation strategy, born and simultaneously gave birth to its continuance.</li>
	<li><strong><a href="Naive progress narrative.html">Naive progress narrative</a></strong></li>
	<li><strong><a href="No value in maintenance.html">No value in maintenance</a></strong></li>
	<li><strong><a href="Oppressive tyrannies for the good of its victims.html">Oppressive tyrannies for the good of its victims</a></strong></li>
	<li><strong><a href="Profit.html">Profit</a></strong> - It is to many a foreign notion that such a thing as profit can ever be a bad thing.</li>
	<li><strong><a href="Quantification.html">Quantification</a></strong> - It is much simpler to optimise for that which is measurable and quantifiable. At least for us it is.</li>
	<li><strong><a href="Resources.html">Resources</a></strong></li>
	<li><strong><a href="Sameness.html">Sameness</a></strong> - Homogeneous optimisation.</li>
	<li><strong><a href="Selfishness.html">Selfishness</a></strong></li>
	<li><strong><a href="Sense-making crisis.html">Sense-making crisis</a></strong> - It doesn't make sense that things are going so well and so horribly wrong at the same time. I mean, it does make sense, but on the surface-level it appears not to.</li>
	<li><strong><a href="Slow change.html">Slow change</a></strong></li>
	<li><strong><a href="Tragedy of the vanishing commons.html">Tragedy of the vanishing commons</a></strong> - A simple example, really. Meta-optimise for profit and financial gain, optimise land-use for maximum privatisation and productivity.</li>
	<li><strong><a href="Transportation infrastructure.html">Transportation infrastructure</a></strong> - Meta-optimise for individual freedom, optimise infrastructure for personal motor vehicles.</li>
	<li><strong><a href="Unpaid important labour.html">Unpaid important labour</a></strong> - A clear example of our meta-optimisations not trickling down the way we intend them to. Because we do care about women, children, and the elderly, right?</li>
	<li><strong><a href="Violence.html">Violence</a></strong> - So much violence to arrive nowhere in particular.</li>
	<li><strong><a href="Wisdom crisis.html">Wisdom crisis</a></strong> - Wisdom could be described as the lifelong mastery of meta-optimisation.</li>
	<li><strong><a href="Yuppie dystopia.html">Yuppie dystopia</a></strong> - Here we are.</li>
</ul>
<br>
<br>
<br>
</body></html>